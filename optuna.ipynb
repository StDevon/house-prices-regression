{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of X: (1430, 342)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    RobustScaler, \n",
    "    FunctionTransformer, \n",
    "    OrdinalEncoder\n",
    ")\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/train_rm_OL.csv')\n",
    "\n",
    "# Load Data (assuming df is already loaded)\n",
    "target = \"SalePrice\"\n",
    "\n",
    "# Split X and y\n",
    "y = np.log1p(df[target])  # Log-transforming the target\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# Define categorical & numerical columns\n",
    "ordinal_columns = [\n",
    "    \"OverallQual\", \"OverallCond\", \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \n",
    "    \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"HeatingQC\", \"KitchenQual\", \n",
    "    \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"PoolQC\"\n",
    "]\n",
    "ordinal_columns = [col for col in ordinal_columns if col in X.columns]  # Ensure they exist in data\n",
    "\n",
    "nominal_columns = [\n",
    "    col for col in X.select_dtypes(include=[\"object\", \"category\"]).columns \n",
    "    if col not in ordinal_columns\n",
    "]\n",
    "numerical_columns = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "\n",
    "ordinal_mappings = {\n",
    "    \"ExterQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"ExterCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"BsmtQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"BsmtCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"HeatingQC\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"KitchenQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"FireplaceQu\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"GarageQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"GarageCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"PoolQC\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "    \"OverallQual\": {i: i for i in range(1, 11)},\n",
    "    \"OverallCond\": {i: i for i in range(1, 11)},\n",
    "    \"BsmtExposure\": {\"Gd\": 4, \"Av\": 3, \"Mn\": 2, \"No\": 1, \"NA\": 0},\n",
    "    \"BsmtFinType1\": {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"NA\": 0},\n",
    "    \"BsmtFinType2\": {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"NA\": 0}\n",
    "}\n",
    "\n",
    "ordinal_transformers = []\n",
    "for col in ordinal_columns:\n",
    "    if col in ordinal_mappings:\n",
    "        ordinal_transformers.append(\n",
    "            (f'ord_{col}', \n",
    "             OrdinalEncoder(\n",
    "                 categories=[list(ordinal_mappings[col].keys())],\n",
    "                 handle_unknown='use_encoded_value',\n",
    "                 unknown_value=-1\n",
    "             ), \n",
    "             [col])\n",
    "        )\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([('log', FunctionTransformer(np.log1p, validate=True)),\n",
    "            (\"scaler\", RobustScaler())  # Scale numerical data after log\n",
    "        ]), numerical_columns),\n",
    "        (\"nom\", OneHotEncoder(handle_unknown=\"ignore\"), nominal_columns),\n",
    "    ] + ordinal_transformers\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "])\n",
    "\n",
    "X_transformed = pipeline.fit_transform(X, y)\n",
    "\n",
    "print(f\"Final shape of X: {X_transformed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 10:27:17,644] A new study created in memory with name: no-name-7127d6fd-fca7-4db7-aa7b-fd4ff65e4486\n",
      "[I 2025-03-10 10:27:29,480] Trial 0 finished with value: 0.4565712885122841 and parameters: {'layer1': 29, 'layer2': 25, 'alpha': 0.0005166807702824, 'learning_rate': 0.00011851319198179293}. Best is trial 0 with value: 0.4565712885122841.\n",
      "[I 2025-03-10 10:27:44,480] Trial 1 finished with value: 0.35071006850768854 and parameters: {'layer1': 30, 'layer2': 18, 'alpha': 0.00036281372001573207, 'learning_rate': 0.00011203209541024333}. Best is trial 0 with value: 0.4565712885122841.\n",
      "[I 2025-03-10 10:27:48,351] Trial 2 finished with value: 0.6979103035718482 and parameters: {'layer1': 25, 'layer2': 13, 'alpha': 0.00918036749079353, 'learning_rate': 0.006261915071886201}. Best is trial 2 with value: 0.6979103035718482.\n",
      "[I 2025-03-10 10:27:54,941] Trial 3 finished with value: 0.5401662399524081 and parameters: {'layer1': 22, 'layer2': 10, 'alpha': 0.0011258738806291812, 'learning_rate': 0.003562750714225477}. Best is trial 2 with value: 0.6979103035718482.\n",
      "[I 2025-03-10 10:28:01,728] Trial 4 finished with value: 0.4891042902756208 and parameters: {'layer1': 26, 'layer2': 31, 'alpha': 0.003181647958560663, 'learning_rate': 0.00033585354512728456}. Best is trial 2 with value: 0.6979103035718482.\n",
      "[I 2025-03-10 10:28:06,437] Trial 5 finished with value: 0.6101206442158313 and parameters: {'layer1': 15, 'layer2': 15, 'alpha': 0.00012378136451426483, 'learning_rate': 0.0006221312586614347}. Best is trial 2 with value: 0.6979103035718482.\n",
      "[I 2025-03-10 10:28:10,655] Trial 6 finished with value: 0.6707944217064973 and parameters: {'layer1': 28, 'layer2': 25, 'alpha': 0.0002148434426809853, 'learning_rate': 0.0013439111386427728}. Best is trial 2 with value: 0.6979103035718482.\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-03-10 10:28:25,332] Trial 7 finished with value: 0.78369629314054 and parameters: {'layer1': 11, 'layer2': 26, 'alpha': 6.686498734118085, 'learning_rate': 0.0012227538546077939}. Best is trial 7 with value: 0.78369629314054.\n",
      "[I 2025-03-10 10:28:28,209] Trial 8 finished with value: 0.7474007330951151 and parameters: {'layer1': 15, 'layer2': 24, 'alpha': 0.005911306887939846, 'learning_rate': 0.011484107195089438}. Best is trial 7 with value: 0.78369629314054.\n",
      "[I 2025-03-10 10:28:32,692] Trial 9 finished with value: 0.7739941649820931 and parameters: {'layer1': 30, 'layer2': 32, 'alpha': 0.00021097518944064526, 'learning_rate': 0.0138876688143175}. Best is trial 7 with value: 0.78369629314054.\n",
      "[I 2025-03-10 10:28:37,182] Trial 10 finished with value: 0.8222194127210415 and parameters: {'layer1': 10, 'layer2': 21, 'alpha': 9.695298712812722, 'learning_rate': 0.06462488268063621}. Best is trial 10 with value: 0.8222194127210415.\n",
      "[I 2025-03-10 10:28:40,092] Trial 11 finished with value: 0.6915146398479004 and parameters: {'layer1': 10, 'layer2': 21, 'alpha': 9.972187044750477, 'learning_rate': 0.08762404439567886}. Best is trial 10 with value: 0.8222194127210415.\n",
      "[I 2025-03-10 10:28:43,557] Trial 12 finished with value: 0.7407423153401002 and parameters: {'layer1': 10, 'layer2': 28, 'alpha': 9.392954736361482, 'learning_rate': 0.04721939569822105}. Best is trial 10 with value: 0.8222194127210415.\n",
      "[I 2025-03-10 10:28:52,030] Trial 13 finished with value: 0.8148819166624157 and parameters: {'layer1': 16, 'layer2': 19, 'alpha': 0.7012593964300039, 'learning_rate': 0.0014013130708690272}. Best is trial 10 with value: 0.8222194127210415.\n",
      "[I 2025-03-10 10:28:55,640] Trial 14 finished with value: 0.7938430395622091 and parameters: {'layer1': 16, 'layer2': 20, 'alpha': 0.3554216605468853, 'learning_rate': 0.028487324980859534}. Best is trial 10 with value: 0.8222194127210415.\n",
      "[I 2025-03-10 10:29:04,932] Trial 15 finished with value: 0.8227584389247815 and parameters: {'layer1': 19, 'layer2': 17, 'alpha': 0.7316176605731575, 'learning_rate': 0.00180039140510882}. Best is trial 15 with value: 0.8227584389247815.\n",
      "[I 2025-03-10 10:29:10,817] Trial 16 finished with value: 0.8082201975087988 and parameters: {'layer1': 20, 'layer2': 16, 'alpha': 0.8434941720059724, 'learning_rate': 0.003548811921110567}. Best is trial 15 with value: 0.8227584389247815.\n",
      "[I 2025-03-10 10:29:15,125] Trial 17 finished with value: 0.8362795292948546 and parameters: {'layer1': 20, 'layer2': 22, 'alpha': 0.11230150178900127, 'learning_rate': 0.015073594245598931}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:19,008] Trial 18 finished with value: 0.833851858182691 and parameters: {'layer1': 20, 'layer2': 13, 'alpha': 0.12194073853815218, 'learning_rate': 0.018041273242330288}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:22,468] Trial 19 finished with value: 0.8337131039003769 and parameters: {'layer1': 23, 'layer2': 10, 'alpha': 0.06958289748893991, 'learning_rate': 0.024172390521226647}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:26,231] Trial 20 finished with value: 0.806696836308461 and parameters: {'layer1': 18, 'layer2': 13, 'alpha': 0.05416226471002138, 'learning_rate': 0.007819080940759567}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:31,363] Trial 21 finished with value: 0.8122566087049968 and parameters: {'layer1': 22, 'layer2': 10, 'alpha': 0.07686656708505891, 'learning_rate': 0.02367504447478939}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:36,556] Trial 22 finished with value: 0.8221944531623329 and parameters: {'layer1': 24, 'layer2': 13, 'alpha': 0.14484955775657404, 'learning_rate': 0.02817295532846997}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:41,970] Trial 23 finished with value: 0.785138104845674 and parameters: {'layer1': 22, 'layer2': 11, 'alpha': 0.020758283846666226, 'learning_rate': 0.015831693678649804}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:48,772] Trial 24 finished with value: 0.8013834370710384 and parameters: {'layer1': 32, 'layer2': 23, 'alpha': 0.22097035948360674, 'learning_rate': 0.043871340533740956}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:51,998] Trial 25 finished with value: 0.7355726083375376 and parameters: {'layer1': 18, 'layer2': 14, 'alpha': 0.021043133601729637, 'learning_rate': 0.006587227861076214}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:55,571] Trial 26 finished with value: 0.6466144235278314 and parameters: {'layer1': 23, 'layer2': 12, 'alpha': 2.6095597276260767, 'learning_rate': 0.020413646678941855}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:29:58,816] Trial 27 finished with value: 0.7963335907543314 and parameters: {'layer1': 20, 'layer2': 28, 'alpha': 0.07873293319568082, 'learning_rate': 0.00935130362850266}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:01,312] Trial 28 finished with value: 0.7198369419592872 and parameters: {'layer1': 27, 'layer2': 16, 'alpha': 0.0336834816575697, 'learning_rate': 0.050219841151450666}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:06,354] Trial 29 finished with value: 0.7963951858578062 and parameters: {'layer1': 24, 'layer2': 23, 'alpha': 0.14814424160499703, 'learning_rate': 0.004642542803507968}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:09,600] Trial 30 finished with value: 0.6806954192898396 and parameters: {'layer1': 21, 'layer2': 11, 'alpha': 2.0982780360719575, 'learning_rate': 0.03351791396338172}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:17,088] Trial 31 finished with value: 0.807763700045531 and parameters: {'layer1': 18, 'layer2': 18, 'alpha': 0.4418784178003761, 'learning_rate': 0.0007628826021796888}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:24,968] Trial 32 finished with value: 0.5412693293268429 and parameters: {'layer1': 20, 'layer2': 17, 'alpha': 0.1798782988868281, 'learning_rate': 0.00017047192629708258}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:29,654] Trial 33 finished with value: 0.7678959977610613 and parameters: {'layer1': 19, 'layer2': 15, 'alpha': 2.073558715729222, 'learning_rate': 0.013891885856963014}. Best is trial 17 with value: 0.8362795292948546.\n",
      "[I 2025-03-10 10:30:39,295] Trial 34 finished with value: 0.838418255234252 and parameters: {'layer1': 25, 'layer2': 12, 'alpha': 0.9927873223014795, 'learning_rate': 0.0018293620508898654}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:30:43,745] Trial 35 finished with value: 0.6957158545123965 and parameters: {'layer1': 25, 'layer2': 12, 'alpha': 0.010692451410758547, 'learning_rate': 0.0023359845828904596}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:30:46,927] Trial 36 finished with value: 0.7050019241187157 and parameters: {'layer1': 26, 'layer2': 10, 'alpha': 0.001097814056029038, 'learning_rate': 0.0054086603530256435}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:30:50,570] Trial 37 finished with value: 0.7170396193880249 and parameters: {'layer1': 23, 'layer2': 12, 'alpha': 0.04204595121377963, 'learning_rate': 0.0023264697777984397}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:30:56,267] Trial 38 finished with value: 0.6550929871516231 and parameters: {'layer1': 29, 'layer2': 14, 'alpha': 0.09002789419523832, 'learning_rate': 0.00040798185268839523}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:31:01,928] Trial 39 finished with value: 0.7757954631380718 and parameters: {'layer1': 25, 'layer2': 10, 'alpha': 1.392309828228877, 'learning_rate': 0.00959182612431673}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:31:06,078] Trial 40 finished with value: 0.8176581399823348 and parameters: {'layer1': 21, 'layer2': 22, 'alpha': 0.37184162835362156, 'learning_rate': 0.020282633408513148}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:31:17,980] Trial 41 finished with value: 0.7938646537253915 and parameters: {'layer1': 13, 'layer2': 19, 'alpha': 4.294476561686377, 'learning_rate': 0.0022275513541188357}. Best is trial 34 with value: 0.838418255234252.\n",
      "[I 2025-03-10 10:31:26,932] Trial 42 finished with value: 0.8444195287496612 and parameters: {'layer1': 17, 'layer2': 14, 'alpha': 0.8418062607346753, 'learning_rate': 0.0008047954534664058}. Best is trial 42 with value: 0.8444195287496612.\n",
      "[I 2025-03-10 10:31:32,751] Trial 43 finished with value: 0.7151371910855318 and parameters: {'layer1': 17, 'layer2': 14, 'alpha': 0.2847963511263796, 'learning_rate': 0.0008259919066863713}. Best is trial 42 with value: 0.8444195287496612.\n",
      "[I 2025-03-10 10:31:47,343] Trial 44 finished with value: 0.8057921296770768 and parameters: {'layer1': 23, 'layer2': 11, 'alpha': 1.156558257212636, 'learning_rate': 0.00032729594105719464}. Best is trial 42 with value: 0.8444195287496612.\n",
      "[I 2025-03-10 10:31:54,273] Trial 45 finished with value: 0.47057418933258255 and parameters: {'layer1': 13, 'layer2': 13, 'alpha': 0.01603463841887997, 'learning_rate': 0.0005087759555475078}. Best is trial 42 with value: 0.8444195287496612.\n",
      "[I 2025-03-10 10:31:58,818] Trial 46 finished with value: 0.6755943829555164 and parameters: {'layer1': 27, 'layer2': 26, 'alpha': 0.004167047728899378, 'learning_rate': 0.0009881396890689697}. Best is trial 42 with value: 0.8444195287496612.\n",
      "[I 2025-03-10 10:32:02,679] Trial 47 finished with value: 0.601877243926897 and parameters: {'layer1': 14, 'layer2': 15, 'alpha': 0.10565209969285591, 'learning_rate': 0.09866611748199025}. Best is trial 42 with value: 0.8444195287496612.\n",
      "[I 2025-03-10 10:32:09,090] Trial 48 finished with value: 0.8209324887503102 and parameters: {'layer1': 22, 'layer2': 11, 'alpha': 0.5908954577253632, 'learning_rate': 0.004016957997698574}. Best is trial 42 with value: 0.8444195287496612.\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Work\\Data Science\\House Prices - Adv Regression\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-03-10 10:32:27,118] Trial 49 finished with value: 0.7650159058074465 and parameters: {'layer1': 17, 'layer2': 20, 'alpha': 3.959740159992514, 'learning_rate': 0.0002170147038807399}. Best is trial 42 with value: 0.8444195287496612.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 0.8444195287496612\n",
      "Best hyperparameters: {'layer1': 17, 'layer2': 14, 'alpha': 0.8418062607346753, 'learning_rate': 0.0008047954534664058}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"hidden_layer_sizes\": (\n",
    "            trial.suggest_int(\"layer1\", 10, 32),\n",
    "            trial.suggest_int(\"layer2\", 10, 32),\n",
    "        ),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e1, log=True),\n",
    "        \"learning_rate_init\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "    }\n",
    "    model = MLPRegressor(**params, max_iter=1000)\n",
    "    return sklearn.model_selection.cross_val_score(model, X_transformed, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print best trial\n",
    "trial = study.best_trial\n",
    "print(\"Best R2:\", trial.value)\n",
    "print(\"Best hyperparameters:\", trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 10:32:27,141] A new study created in memory with name: no-name-aa07cc15-0c2a-4764-bbe8-8e69d1538c3f\n",
      "[I 2025-03-10 10:32:27,240] Trial 5 finished with value: -0.002365061359100018 and parameters: {'model_type': 'ElasticNet', 'alpha': 4.3072561920707, 'l1_ratio': 0.20304078127425607}. Best is trial 5 with value: -0.002365061359100018.\n",
      "[I 2025-03-10 10:32:27,264] Trial 2 finished with value: 0.6683902643810744 and parameters: {'model_type': 'Lasso', 'alpha': 0.11328020555609132}. Best is trial 2 with value: 0.6683902643810744.\n",
      "[I 2025-03-10 10:32:27,269] Trial 6 finished with value: -0.002365061359100018 and parameters: {'model_type': 'ElasticNet', 'alpha': 6.58915800819121, 'l1_ratio': 0.6526597553629435}. Best is trial 2 with value: 0.6683902643810744.\n",
      "[I 2025-03-10 10:32:27,328] Trial 8 finished with value: 0.6823498312081453 and parameters: {'model_type': 'ElasticNet', 'alpha': 0.21045462836364512, 'l1_ratio': 0.47475329573773084}. Best is trial 8 with value: 0.6823498312081453.\n",
      "[I 2025-03-10 10:32:27,547] Trial 4 finished with value: 0.8923904525361225 and parameters: {'model_type': 'ElasticNet', 'alpha': 0.006871582951692133, 'l1_ratio': 0.8104265287941944}. Best is trial 4 with value: 0.8923904525361225.\n",
      "[I 2025-03-10 10:32:27,883] Trial 0 finished with value: 0.8955356586524603 and parameters: {'model_type': 'Ridge', 'alpha': 0.10685554162502076}. Best is trial 0 with value: 0.8955356586524603.\n",
      "[I 2025-03-10 10:32:27,936] Trial 3 finished with value: 0.9055202904272294 and parameters: {'model_type': 'Ridge', 'alpha': 1.0287340646350924}. Best is trial 3 with value: 0.9055202904272294.\n",
      "[I 2025-03-10 10:32:27,966] Trial 9 finished with value: 0.9105674973159676 and parameters: {'model_type': 'Ridge', 'alpha': 2.7043879035334184}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:27,981] Trial 14 finished with value: -0.002365061359100018 and parameters: {'model_type': 'ElasticNet', 'alpha': 1.2904461256737547, 'l1_ratio': 0.8074286302509512}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,027] Trial 10 finished with value: 0.8919268618636442 and parameters: {'model_type': 'Ridge', 'alpha': 0.00014203722804351758}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,138] Trial 11 finished with value: 0.8973327661622047 and parameters: {'model_type': 'Ridge', 'alpha': 0.19433443303401907}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,280] Trial 17 finished with value: 0.887166775169501 and parameters: {'model_type': 'Lasso', 'alpha': 0.008926459916327786}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,362] Trial 12 finished with value: 0.896184619591058 and parameters: {'model_type': 'Ridge', 'alpha': 0.13761003039269035}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,664] Trial 13 finished with value: 0.8921211201391743 and parameters: {'model_type': 'Ridge', 'alpha': 0.0003096060479941147}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,740] Trial 15 finished with value: 0.9061086276354293 and parameters: {'model_type': 'Ridge', 'alpha': 1.148217129403493}. Best is trial 9 with value: 0.9105674973159676.\n",
      "[I 2025-03-10 10:32:28,769] Trial 1 finished with value: 0.9154319527570476 and parameters: {'model_type': 'Lasso', 'alpha': 0.00021477016210058697}. Best is trial 1 with value: 0.9154319527570476.\n",
      "[I 2025-03-10 10:32:28,795] Trial 16 finished with value: 0.9158307789657879 and parameters: {'model_type': 'ElasticNet', 'alpha': 0.0012367146203142798, 'l1_ratio': 0.7387910360645321}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:28,879] Trial 18 finished with value: 0.8922301718261718 and parameters: {'model_type': 'Ridge', 'alpha': 0.006250560056916073}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:28,974] Trial 19 finished with value: 0.9056491183532843 and parameters: {'model_type': 'Ridge', 'alpha': 1.0513040903775368}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:29,021] Trial 20 finished with value: 0.9074275076890638 and parameters: {'model_type': 'Ridge', 'alpha': 1.4609562609588473}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:29,187] Trial 7 finished with value: 0.9122812942825596 and parameters: {'model_type': 'ElasticNet', 'alpha': 0.0005175719509280691, 'l1_ratio': 0.20961754847855085}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:29,225] Trial 21 finished with value: 0.9063466316803005 and parameters: {'model_type': 'Ridge', 'alpha': 1.2004128930777376}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:29,266] Trial 22 finished with value: 0.9071206935607063 and parameters: {'model_type': 'Ridge', 'alpha': 1.380797767782698}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:29,640] Trial 23 finished with value: 0.9150309086136705 and parameters: {'model_type': 'Lasso', 'alpha': 0.0010388055329009214}. Best is trial 16 with value: 0.9158307789657879.\n",
      "[I 2025-03-10 10:32:29,658] Trial 24 finished with value: 0.9160115065804474 and parameters: {'model_type': 'Lasso', 'alpha': 0.000921813913034913}. Best is trial 24 with value: 0.9160115065804474.\n",
      "[I 2025-03-10 10:32:29,828] Trial 25 finished with value: 0.9169053796783526 and parameters: {'model_type': 'Lasso', 'alpha': 0.000804687849357935}. Best is trial 25 with value: 0.9169053796783526.\n",
      "[I 2025-03-10 10:32:29,932] Trial 26 finished with value: 0.9164325321913885 and parameters: {'model_type': 'Lasso', 'alpha': 0.0008659756999075086}. Best is trial 25 with value: 0.9169053796783526.\n",
      "[I 2025-03-10 10:32:29,950] Trial 27 finished with value: 0.9160802880860436 and parameters: {'model_type': 'Lasso', 'alpha': 0.0009130645406387061}. Best is trial 25 with value: 0.9169053796783526.\n",
      "[I 2025-03-10 10:32:30,005] Trial 28 finished with value: 0.9148481180491425 and parameters: {'model_type': 'Lasso', 'alpha': 0.0010599707703490555}. Best is trial 25 with value: 0.9169053796783526.\n",
      "[I 2025-03-10 10:32:30,066] Trial 29 finished with value: 0.9155830349616852 and parameters: {'model_type': 'Lasso', 'alpha': 0.0009748012188144231}. Best is trial 25 with value: 0.9169053796783526.\n",
      "[I 2025-03-10 10:32:30,232] Trial 30 finished with value: 0.9179561746932965 and parameters: {'model_type': 'Lasso', 'alpha': 0.0005908210617479256}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,280] Trial 32 finished with value: 0.90722774038588 and parameters: {'model_type': 'Lasso', 'alpha': 0.001890256876539214}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,374] Trial 31 finished with value: 0.9110754888939077 and parameters: {'model_type': 'Lasso', 'alpha': 0.0014584629048474016}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,466] Trial 33 finished with value: 0.9053744187336916 and parameters: {'model_type': 'Lasso', 'alpha': 0.002165026405729054}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,545] Trial 35 finished with value: 0.9021616702532486 and parameters: {'model_type': 'Lasso', 'alpha': 0.0029226971508566828}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,546] Trial 34 finished with value: 0.905291453044093 and parameters: {'model_type': 'Lasso', 'alpha': 0.002181487075277756}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,572] Trial 36 finished with value: 0.9008100735610727 and parameters: {'model_type': 'Lasso', 'alpha': 0.00328396686471207}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,606] Trial 41 finished with value: 0.844118985655574 and parameters: {'model_type': 'Lasso', 'alpha': 0.027009210119738475}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,674] Trial 37 finished with value: 0.9034176704021011 and parameters: {'model_type': 'Lasso', 'alpha': 0.0025887000403694836}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,689] Trial 42 finished with value: 0.8379368589441609 and parameters: {'model_type': 'Lasso', 'alpha': 0.029574831593914486}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,696] Trial 43 finished with value: 0.8347411283419364 and parameters: {'model_type': 'Lasso', 'alpha': 0.031001060698636448}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,725] Trial 44 finished with value: 0.8404526727400233 and parameters: {'model_type': 'Lasso', 'alpha': 0.02852396605049907}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,835] Trial 38 finished with value: 0.9021581744463582 and parameters: {'model_type': 'Lasso', 'alpha': 0.0029237015123692728}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:30,864] Trial 39 finished with value: 0.9024182526484241 and parameters: {'model_type': 'Lasso', 'alpha': 0.0028497048947786273}. Best is trial 30 with value: 0.9179561746932965.\n",
      "[I 2025-03-10 10:32:31,691] Trial 49 finished with value: 0.9180679182187615 and parameters: {'model_type': 'Lasso', 'alpha': 0.00044069834440268123}. Best is trial 49 with value: 0.9180679182187615.\n",
      "[I 2025-03-10 10:32:31,697] Trial 47 finished with value: 0.9180377815989301 and parameters: {'model_type': 'Lasso', 'alpha': 0.0004292890352711118}. Best is trial 49 with value: 0.9180679182187615.\n",
      "[I 2025-03-10 10:32:31,710] Trial 48 finished with value: 0.9181074884505007 and parameters: {'model_type': 'Lasso', 'alpha': 0.0005069943346946719}. Best is trial 48 with value: 0.9181074884505007.\n",
      "[I 2025-03-10 10:32:31,970] Trial 46 finished with value: 0.9171418579542336 and parameters: {'model_type': 'Lasso', 'alpha': 0.0003172995659971542}. Best is trial 48 with value: 0.9181074884505007.\n",
      "[I 2025-03-10 10:32:32,552] Trial 40 finished with value: 0.9102690780065466 and parameters: {'model_type': 'Lasso', 'alpha': 0.00010629289294556487}. Best is trial 48 with value: 0.9181074884505007.\n",
      "[I 2025-03-10 10:32:32,825] Trial 45 finished with value: 0.9105169816031088 and parameters: {'model_type': 'Lasso', 'alpha': 0.00010937915266681506}. Best is trial 48 with value: 0.9181074884505007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model and parameters: {'model_type': 'Lasso', 'alpha': 0.0005069943346946719}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure the features are scaled\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "def objective(trial):\n",
    "    # Choose model type\n",
    "    model_type = trial.suggest_categorical(\"model_type\", [\"Ridge\", \"Lasso\", \"ElasticNet\"])\n",
    "    \n",
    "    # Choose regularization strength (alpha)\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-4, 10.0, log=True)\n",
    "    \n",
    "    # Define model based on choice\n",
    "    if model_type == \"Ridge\":\n",
    "        model = Ridge(alpha=alpha)\n",
    "    elif model_type == \"Lasso\":\n",
    "        model = Lasso(alpha=alpha)\n",
    "    else:  # ElasticNet\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.1, 0.9)  # Mix between Lasso (1.0) & Ridge (0.0)\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "\n",
    "    # Pipeline to standardize data (important for regularization)\n",
    "    # pipeline = make_pipeline(StandardScaler(), model)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    score = cross_val_score(model, X_transformed, y, cv=5, scoring=\"r2\").mean()\n",
    "    \n",
    "    return score  # Optuna maximizes RÂ²\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "\n",
    "print(\"Best model and parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 10:32:33,775] A new study created in memory with name: no-name-6f89e738-5988-43a9-92b7-614289888a10\n",
      "[I 2025-03-10 10:32:35,891] Trial 0 finished with value: 0.8440124694472709 and parameters: {'n_estimators': 4, 'max_depth': 17}. Best is trial 0 with value: 0.8440124694472709.\n",
      "[I 2025-03-10 10:32:36,939] Trial 1 finished with value: 0.7323836064835201 and parameters: {'n_estimators': 6, 'max_depth': 3}. Best is trial 0 with value: 0.8440124694472709.\n",
      "[I 2025-03-10 10:32:38,789] Trial 2 finished with value: 0.8691640793933285 and parameters: {'n_estimators': 17, 'max_depth': 21}. Best is trial 2 with value: 0.8691640793933285.\n",
      "[I 2025-03-10 10:32:40,122] Trial 3 finished with value: 0.8695377425589881 and parameters: {'n_estimators': 15, 'max_depth': 13}. Best is trial 3 with value: 0.8695377425589881.\n",
      "[I 2025-03-10 10:32:40,555] Trial 4 finished with value: 0.8611667006620538 and parameters: {'n_estimators': 7, 'max_depth': 9}. Best is trial 3 with value: 0.8695377425589881.\n",
      "[I 2025-03-10 10:32:42,456] Trial 5 finished with value: 0.8719854150721978 and parameters: {'n_estimators': 19, 'max_depth': 31}. Best is trial 5 with value: 0.8719854150721978.\n",
      "[I 2025-03-10 10:32:43,473] Trial 6 finished with value: 0.8588859549600334 and parameters: {'n_estimators': 10, 'max_depth': 28}. Best is trial 5 with value: 0.8719854150721978.\n",
      "[I 2025-03-10 10:32:44,933] Trial 7 finished with value: 0.8685320177329506 and parameters: {'n_estimators': 15, 'max_depth': 18}. Best is trial 5 with value: 0.8719854150721978.\n",
      "[I 2025-03-10 10:32:45,934] Trial 8 finished with value: 0.8623639801133134 and parameters: {'n_estimators': 10, 'max_depth': 22}. Best is trial 5 with value: 0.8719854150721978.\n",
      "[I 2025-03-10 10:32:46,374] Trial 9 finished with value: 0.8305743060982798 and parameters: {'n_estimators': 4, 'max_depth': 32}. Best is trial 5 with value: 0.8719854150721978.\n",
      "[I 2025-03-10 10:32:48,354] Trial 10 finished with value: 0.8735945870299784 and parameters: {'n_estimators': 20, 'max_depth': 27}. Best is trial 10 with value: 0.8735945870299784.\n",
      "[I 2025-03-10 10:32:50,321] Trial 11 finished with value: 0.8724879076474835 and parameters: {'n_estimators': 20, 'max_depth': 27}. Best is trial 10 with value: 0.8735945870299784.\n",
      "[I 2025-03-10 10:32:52,317] Trial 12 finished with value: 0.8703281480594882 and parameters: {'n_estimators': 20, 'max_depth': 24}. Best is trial 10 with value: 0.8735945870299784.\n",
      "[I 2025-03-10 10:32:53,739] Trial 13 finished with value: 0.8704594530018017 and parameters: {'n_estimators': 14, 'max_depth': 27}. Best is trial 10 with value: 0.8735945870299784.\n",
      "[I 2025-03-10 10:32:55,552] Trial 14 finished with value: 0.8760342646518191 and parameters: {'n_estimators': 18, 'max_depth': 26}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:32:57,223] Trial 15 finished with value: 0.8686942417808019 and parameters: {'n_estimators': 17, 'max_depth': 24}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:32:58,289] Trial 16 finished with value: 0.8672145178631661 and parameters: {'n_estimators': 12, 'max_depth': 13}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:00,135] Trial 17 finished with value: 0.8740602211922471 and parameters: {'n_estimators': 17, 'max_depth': 30}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:02,073] Trial 18 finished with value: 0.8743659413547895 and parameters: {'n_estimators': 17, 'max_depth': 32}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:04,039] Trial 19 finished with value: 0.8707895398298804 and parameters: {'n_estimators': 18, 'max_depth': 20}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:05,506] Trial 20 finished with value: 0.868140954163153 and parameters: {'n_estimators': 13, 'max_depth': 32}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:07,302] Trial 21 finished with value: 0.8652468396206687 and parameters: {'n_estimators': 16, 'max_depth': 29}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:09,270] Trial 22 finished with value: 0.8688287423731783 and parameters: {'n_estimators': 18, 'max_depth': 25}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:11,047] Trial 23 finished with value: 0.8709421460236608 and parameters: {'n_estimators': 16, 'max_depth': 30}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:12,474] Trial 24 finished with value: 0.8661406694659265 and parameters: {'n_estimators': 13, 'max_depth': 32}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:14,439] Trial 25 finished with value: 0.8701540992211617 and parameters: {'n_estimators': 18, 'max_depth': 25}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:15,675] Trial 26 finished with value: 0.8653003047434634 and parameters: {'n_estimators': 11, 'max_depth': 29}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:15,954] Trial 27 finished with value: 0.8187287474435354 and parameters: {'n_estimators': 2, 'max_depth': 14}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:16,036] Trial 28 finished with value: 0.45990070818164563 and parameters: {'n_estimators': 15, 'max_depth': 1}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:16,456] Trial 29 finished with value: 0.8573339399882787 and parameters: {'n_estimators': 8, 'max_depth': 8}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:18,354] Trial 30 finished with value: 0.8728647120587578 and parameters: {'n_estimators': 17, 'max_depth': 18}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:20,723] Trial 31 finished with value: 0.872379917798939 and parameters: {'n_estimators': 20, 'max_depth': 27}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:22,874] Trial 32 finished with value: 0.8721497211851725 and parameters: {'n_estimators': 19, 'max_depth': 30}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:24,969] Trial 33 finished with value: 0.8722288913868453 and parameters: {'n_estimators': 19, 'max_depth': 22}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:26,706] Trial 34 finished with value: 0.8670329910760735 and parameters: {'n_estimators': 16, 'max_depth': 26}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:28,674] Trial 35 finished with value: 0.8719542803454974 and parameters: {'n_estimators': 18, 'max_depth': 29}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:30,206] Trial 36 finished with value: 0.8666622364492751 and parameters: {'n_estimators': 14, 'max_depth': 23}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:32,055] Trial 37 finished with value: 0.868962940478674 and parameters: {'n_estimators': 17, 'max_depth': 30}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:34,084] Trial 38 finished with value: 0.8711982914890297 and parameters: {'n_estimators': 19, 'max_depth': 28}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:36,278] Trial 39 finished with value: 0.8714521522044993 and parameters: {'n_estimators': 20, 'max_depth': 20}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:37,997] Trial 40 finished with value: 0.8745429314604042 and parameters: {'n_estimators': 16, 'max_depth': 31}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:39,718] Trial 41 finished with value: 0.8693470482444144 and parameters: {'n_estimators': 16, 'max_depth': 31}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:41,673] Trial 42 finished with value: 0.8712240632946996 and parameters: {'n_estimators': 18, 'max_depth': 32}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:43,306] Trial 43 finished with value: 0.8708593359303027 and parameters: {'n_estimators': 15, 'max_depth': 28}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:45,115] Trial 44 finished with value: 0.8697383296336838 and parameters: {'n_estimators': 17, 'max_depth': 26}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:46,305] Trial 45 finished with value: 0.8683071074697608 and parameters: {'n_estimators': 19, 'max_depth': 9}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:47,812] Trial 46 finished with value: 0.8679597565631625 and parameters: {'n_estimators': 14, 'max_depth': 31}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:49,951] Trial 47 finished with value: 0.8725334103624034 and parameters: {'n_estimators': 20, 'max_depth': 26}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:50,803] Trial 48 finished with value: 0.8576833607680117 and parameters: {'n_estimators': 8, 'max_depth': 16}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:52,657] Trial 49 finished with value: 0.8725623008526263 and parameters: {'n_estimators': 17, 'max_depth': 30}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:54,705] Trial 50 finished with value: 0.8699820843737713 and parameters: {'n_estimators': 19, 'max_depth': 23}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:56,325] Trial 51 finished with value: 0.8689742142586374 and parameters: {'n_estimators': 15, 'max_depth': 18}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:58,177] Trial 52 finished with value: 0.8713918788183015 and parameters: {'n_estimators': 17, 'max_depth': 28}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:33:59,022] Trial 53 finished with value: 0.8675542527097256 and parameters: {'n_estimators': 16, 'max_depth': 8}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:01,006] Trial 54 finished with value: 0.8723148069334501 and parameters: {'n_estimators': 18, 'max_depth': 32}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:02,802] Trial 55 finished with value: 0.8678276595843878 and parameters: {'n_estimators': 17, 'max_depth': 16}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:04,349] Trial 56 finished with value: 0.8689089663843834 and parameters: {'n_estimators': 13, 'max_depth': 20}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:06,482] Trial 57 finished with value: 0.8707246690481542 and parameters: {'n_estimators': 18, 'max_depth': 25}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:07,707] Trial 58 finished with value: 0.8721239801769437 and parameters: {'n_estimators': 15, 'max_depth': 10}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:08,456] Trial 59 finished with value: 0.8510285518299716 and parameters: {'n_estimators': 5, 'max_depth': 31}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:10,981] Trial 60 finished with value: 0.8719043913683369 and parameters: {'n_estimators': 20, 'max_depth': 29}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:12,987] Trial 61 finished with value: 0.8713159489739908 and parameters: {'n_estimators': 17, 'max_depth': 27}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:14,891] Trial 62 finished with value: 0.87351505807409 and parameters: {'n_estimators': 16, 'max_depth': 29}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:16,784] Trial 63 finished with value: 0.8701584262648886 and parameters: {'n_estimators': 16, 'max_depth': 28}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:18,470] Trial 64 finished with value: 0.8723645746376041 and parameters: {'n_estimators': 14, 'max_depth': 30}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:20,724] Trial 65 finished with value: 0.8747210135387569 and parameters: {'n_estimators': 19, 'max_depth': 31}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:23,032] Trial 66 finished with value: 0.8702817932100606 and parameters: {'n_estimators': 19, 'max_depth': 31}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:24,526] Trial 67 finished with value: 0.8658999712976353 and parameters: {'n_estimators': 12, 'max_depth': 32}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:26,782] Trial 68 finished with value: 0.8732398455249116 and parameters: {'n_estimators': 19, 'max_depth': 29}. Best is trial 14 with value: 0.8760342646518191.\n",
      "[I 2025-03-10 10:34:28,938] Trial 69 finished with value: 0.876338326638529 and parameters: {'n_estimators': 18, 'max_depth': 24}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:31,310] Trial 70 finished with value: 0.8730498860502841 and parameters: {'n_estimators': 20, 'max_depth': 26}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:33,474] Trial 71 finished with value: 0.8720692909390818 and parameters: {'n_estimators': 18, 'max_depth': 29}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:35,588] Trial 72 finished with value: 0.8701928267346194 and parameters: {'n_estimators': 18, 'max_depth': 24}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:37,523] Trial 73 finished with value: 0.8695563805086491 and parameters: {'n_estimators': 16, 'max_depth': 27}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:39,707] Trial 74 finished with value: 0.8670164896619458 and parameters: {'n_estimators': 18, 'max_depth': 31}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:42,015] Trial 75 finished with value: 0.8735034207077099 and parameters: {'n_estimators': 19, 'max_depth': 30}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:43,906] Trial 76 finished with value: 0.8694024397223163 and parameters: {'n_estimators': 16, 'max_depth': 25}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:45,922] Trial 77 finished with value: 0.8662364548184829 and parameters: {'n_estimators': 17, 'max_depth': 28}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:48,249] Trial 78 finished with value: 0.8673034804786912 and parameters: {'n_estimators': 20, 'max_depth': 32}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:50,021] Trial 79 finished with value: 0.867970271357321 and parameters: {'n_estimators': 15, 'max_depth': 30}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:52,255] Trial 80 finished with value: 0.8742145477531604 and parameters: {'n_estimators': 19, 'max_depth': 27}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:54,607] Trial 81 finished with value: 0.8730340485901087 and parameters: {'n_estimators': 19, 'max_depth': 27}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:57,001] Trial 82 finished with value: 0.8694635676148337 and parameters: {'n_estimators': 20, 'max_depth': 23}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:34:59,236] Trial 83 finished with value: 0.8752714307839151 and parameters: {'n_estimators': 19, 'max_depth': 26}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:01,496] Trial 84 finished with value: 0.8691310554300145 and parameters: {'n_estimators': 19, 'max_depth': 26}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:03,655] Trial 85 finished with value: 0.8712302960907706 and parameters: {'n_estimators': 18, 'max_depth': 21}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:05,806] Trial 86 finished with value: 0.8639640470667201 and parameters: {'n_estimators': 18, 'max_depth': 25}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:08,152] Trial 87 finished with value: 0.8714057717359962 and parameters: {'n_estimators': 20, 'max_depth': 24}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:10,429] Trial 88 finished with value: 0.8712174661753522 and parameters: {'n_estimators': 19, 'max_depth': 28}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:11,664] Trial 89 finished with value: 0.8612293275359658 and parameters: {'n_estimators': 10, 'max_depth': 22}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:13,673] Trial 90 finished with value: 0.8704689599878581 and parameters: {'n_estimators': 17, 'max_depth': 27}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:15,824] Trial 91 finished with value: 0.8746122795653063 and parameters: {'n_estimators': 18, 'max_depth': 31}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:18,053] Trial 92 finished with value: 0.8680405354827514 and parameters: {'n_estimators': 18, 'max_depth': 31}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:20,054] Trial 93 finished with value: 0.8722263331316163 and parameters: {'n_estimators': 17, 'max_depth': 32}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:22,306] Trial 94 finished with value: 0.8725105386174888 and parameters: {'n_estimators': 19, 'max_depth': 30}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:24,674] Trial 95 finished with value: 0.873597461344169 and parameters: {'n_estimators': 19, 'max_depth': 28}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:27,040] Trial 96 finished with value: 0.8743009235962262 and parameters: {'n_estimators': 18, 'max_depth': 29}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:29,372] Trial 97 finished with value: 0.8696120148429115 and parameters: {'n_estimators': 17, 'max_depth': 31}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:31,554] Trial 98 finished with value: 0.8705980399096177 and parameters: {'n_estimators': 18, 'max_depth': 29}. Best is trial 69 with value: 0.876338326638529.\n",
      "[I 2025-03-10 10:35:33,740] Trial 99 finished with value: 0.8709603841708322 and parameters: {'n_estimators': 18, 'max_depth': 30}. Best is trial 69 with value: 0.876338326638529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 0.876338326638529\n",
      "Best hyperparameters: {'n_estimators': 18, 'max_depth': 24}\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 2, 20)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 32)\n",
    "    \n",
    "    reg = sklearn.ensemble.RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "    return sklearn.model_selection.cross_val_score(\n",
    "        reg, X_transformed, y, n_jobs=-1, cv=5, scoring=\"r2\"\n",
    "    ).mean()\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best trial\n",
    "trial = study.best_trial\n",
    "print(\"Best R2:\", trial.value)\n",
    "print(\"Best hyperparameters:\", trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 10:35:33,776] A new study created in memory with name: no-name-079410df-cbd6-400a-8365-feb63ed9d081\n",
      "[I 2025-03-10 10:35:35,665] Trial 0 finished with value: 0.8967090493091826 and parameters: {'n_estimators': 889, 'max_depth': 3, 'learning_rate': 0.006697147540639736, 'num_leaves': 352, 'reg_alpha': 0.0032651857532792483, 'reg_lambda': 1.954222128624492}. Best is trial 0 with value: 0.8967090493091826.\n",
      "[I 2025-03-10 10:35:36,411] Trial 1 finished with value: 0.8944421168071036 and parameters: {'n_estimators': 878, 'max_depth': 4, 'learning_rate': 0.06608889810583818, 'num_leaves': 33, 'reg_alpha': 1.7944003526723005, 'reg_lambda': 0.0016320663650815491}. Best is trial 0 with value: 0.8967090493091826.\n",
      "[I 2025-03-10 10:35:37,142] Trial 2 finished with value: 0.9090274268507746 and parameters: {'n_estimators': 415, 'max_depth': 3, 'learning_rate': 0.0926952167056839, 'num_leaves': 241, 'reg_alpha': 0.021743969391415947, 'reg_lambda': 0.009925342539370966}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:38,298] Trial 3 finished with value: 0.9088847594410817 and parameters: {'n_estimators': 560, 'max_depth': 3, 'learning_rate': 0.05904633405567723, 'num_leaves': 629, 'reg_alpha': 0.05027193405280554, 'reg_lambda': 2.7688185447056735}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:38,855] Trial 4 finished with value: 0.9041583595447523 and parameters: {'n_estimators': 853, 'max_depth': 1, 'learning_rate': 0.06449918838289641, 'num_leaves': 24, 'reg_alpha': 0.03804746600012118, 'reg_lambda': 4.854295508938386}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:40,405] Trial 5 finished with value: 0.9052387773334789 and parameters: {'n_estimators': 560, 'max_depth': 3, 'learning_rate': 0.09437578511478825, 'num_leaves': 999, 'reg_alpha': 0.0025952718297902306, 'reg_lambda': 0.004027528464350028}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:41,405] Trial 6 finished with value: 0.9082215393146912 and parameters: {'n_estimators': 918, 'max_depth': 2, 'learning_rate': 0.032400621190073975, 'num_leaves': 443, 'reg_alpha': 0.07931433982407468, 'reg_lambda': 0.08232111918139336}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:42,292] Trial 7 finished with value: 0.9062474640580804 and parameters: {'n_estimators': 842, 'max_depth': 2, 'learning_rate': 0.02589656994383763, 'num_leaves': 433, 'reg_alpha': 0.05134844441862654, 'reg_lambda': 5.882023226536537}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:42,804] Trial 8 finished with value: 0.9035225032356617 and parameters: {'n_estimators': 741, 'max_depth': 1, 'learning_rate': 0.0631307010456344, 'num_leaves': 416, 'reg_alpha': 0.0018244750847053327, 'reg_lambda': 0.03566099935375794}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:43,410] Trial 9 finished with value: 0.9085687289326291 and parameters: {'n_estimators': 515, 'max_depth': 2, 'learning_rate': 0.06569229296583781, 'num_leaves': 402, 'reg_alpha': 0.29312359602140525, 'reg_lambda': 0.021396538640007453}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:43,800] Trial 10 finished with value: 0.8578854682107935 and parameters: {'n_estimators': 338, 'max_depth': 4, 'learning_rate': 0.09829065133329598, 'num_leaves': 185, 'reg_alpha': 6.910351017731329, 'reg_lambda': 0.006587524518777012}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:44,541] Trial 11 finished with value: 0.9068895833612052 and parameters: {'n_estimators': 385, 'max_depth': 3, 'learning_rate': 0.0845327486759847, 'num_leaves': 705, 'reg_alpha': 0.013545890644211673, 'reg_lambda': 0.4928059651587826}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:45,419] Trial 12 finished with value: 0.9065976806733035 and parameters: {'n_estimators': 480, 'max_depth': 3, 'learning_rate': 0.04589213803610912, 'num_leaves': 652, 'reg_alpha': 0.47910593830069104, 'reg_lambda': 0.4523224655825087}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:46,788] Trial 13 finished with value: 0.8997506910890565 and parameters: {'n_estimators': 643, 'max_depth': 4, 'learning_rate': 0.08150668688894644, 'num_leaves': 620, 'reg_alpha': 0.012966213170897257, 'reg_lambda': 0.512220919749708}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:47,643] Trial 14 finished with value: 0.9078825352388395 and parameters: {'n_estimators': 443, 'max_depth': 3, 'learning_rate': 0.0781268951420857, 'num_leaves': 843, 'reg_alpha': 0.01372084024512059, 'reg_lambda': 0.013518701366853602}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:48,279] Trial 15 finished with value: 0.907295664956419 and parameters: {'n_estimators': 618, 'max_depth': 2, 'learning_rate': 0.04836682325187833, 'num_leaves': 239, 'reg_alpha': 0.21062593003456123, 'reg_lambda': 0.09113173810327552}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:49,089] Trial 16 finished with value: 0.9026440982351452 and parameters: {'n_estimators': 301, 'max_depth': 4, 'learning_rate': 0.02597655154174717, 'num_leaves': 584, 'reg_alpha': 0.007187637503741016, 'reg_lambda': 0.00116991378532195}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:50,162] Trial 17 finished with value: 0.9087299911130126 and parameters: {'n_estimators': 752, 'max_depth': 3, 'learning_rate': 0.037569237077614115, 'num_leaves': 226, 'reg_alpha': 0.03072630466709576, 'reg_lambda': 1.3153217212497346}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:50,810] Trial 18 finished with value: 0.8473690476803913 and parameters: {'n_estimators': 422, 'max_depth': 2, 'learning_rate': 0.008858425239606199, 'num_leaves': 879, 'reg_alpha': 0.9808521785777123, 'reg_lambda': 0.25544998092860444}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:52,116] Trial 19 finished with value: 0.8997136230041869 and parameters: {'n_estimators': 552, 'max_depth': 4, 'learning_rate': 0.07469072809143235, 'num_leaves': 537, 'reg_alpha': 0.11455532915899726, 'reg_lambda': 0.04729493035318508}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:53,345] Trial 20 finished with value: 0.9053989402015266 and parameters: {'n_estimators': 705, 'max_depth': 3, 'learning_rate': 0.08900116214614748, 'num_leaves': 751, 'reg_alpha': 0.0055765741916876084, 'reg_lambda': 0.006421183934032545}. Best is trial 2 with value: 0.9090274268507746.\n",
      "[I 2025-03-10 10:35:54,831] Trial 21 finished with value: 0.9091804036566327 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.037322117771552484, 'num_leaves': 255, 'reg_alpha': 0.02381657692915449, 'reg_lambda': 1.6224549706502391}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:35:55,750] Trial 22 finished with value: 0.9091063972459686 and parameters: {'n_estimators': 605, 'max_depth': 3, 'learning_rate': 0.0527058558869285, 'num_leaves': 295, 'reg_alpha': 0.027672552095141936, 'reg_lambda': 1.9052424260042817}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:35:56,947] Trial 23 finished with value: 0.9081004085675304 and parameters: {'n_estimators': 810, 'max_depth': 3, 'learning_rate': 0.019071287247294504, 'num_leaves': 140, 'reg_alpha': 0.02218093164377787, 'reg_lambda': 0.20273595885935788}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:35:57,893] Trial 24 finished with value: 0.908877561853919 and parameters: {'n_estimators': 972, 'max_depth': 2, 'learning_rate': 0.04096923998582726, 'num_leaves': 327, 'reg_alpha': 0.0010672857018078372, 'reg_lambda': 1.2512892180702135}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:35:59,408] Trial 25 finished with value: 0.9059643926736202 and parameters: {'n_estimators': 991, 'max_depth': 3, 'learning_rate': 0.051000267821463385, 'num_leaves': 289, 'reg_alpha': 0.1350849695684562, 'reg_lambda': 3.2256379176864596}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:00,737] Trial 26 finished with value: 0.9017729489611204 and parameters: {'n_estimators': 702, 'max_depth': 4, 'learning_rate': 0.05471642246949759, 'num_leaves': 119, 'reg_alpha': 0.005739236210420601, 'reg_lambda': 9.177695070875744}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:01,697] Trial 27 finished with value: 0.9063567817818802 and parameters: {'n_estimators': 600, 'max_depth': 3, 'learning_rate': 0.0168926852577352, 'num_leaves': 276, 'reg_alpha': 0.02484206733463123, 'reg_lambda': 0.20633518305527135}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:02,475] Trial 28 finished with value: 0.9077960110926357 and parameters: {'n_estimators': 787, 'max_depth': 2, 'learning_rate': 0.07221041712127016, 'num_leaves': 106, 'reg_alpha': 0.07320219273264159, 'reg_lambda': 0.8873339172887861}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:03,182] Trial 29 finished with value: 0.8458081824577312 and parameters: {'n_estimators': 376, 'max_depth': 3, 'learning_rate': 0.007595451291085395, 'num_leaves': 350, 'reg_alpha': 0.00915668021714656, 'reg_lambda': 9.937783855318814}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:05,038] Trial 30 finished with value: 0.9025556574803616 and parameters: {'n_estimators': 933, 'max_depth': 4, 'learning_rate': 0.03354836491070182, 'num_leaves': 506, 'reg_alpha': 0.003688600401278792, 'reg_lambda': 1.9200326120082896}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:05,858] Trial 31 finished with value: 0.9076637617919635 and parameters: {'n_estimators': 544, 'max_depth': 3, 'learning_rate': 0.05718928431702108, 'num_leaves': 191, 'reg_alpha': 0.046841726332729275, 'reg_lambda': 2.6988642419776427}. Best is trial 21 with value: 0.9091804036566327.\n",
      "[I 2025-03-10 10:36:06,634] Trial 32 finished with value: 0.9092595905524172 and parameters: {'n_estimators': 492, 'max_depth': 3, 'learning_rate': 0.059766719431178915, 'num_leaves': 322, 'reg_alpha': 0.017729388440876875, 'reg_lambda': 0.8896739716299361}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:07,386] Trial 33 finished with value: 0.9078532012551463 and parameters: {'n_estimators': 482, 'max_depth': 3, 'learning_rate': 0.04138422535863016, 'num_leaves': 297, 'reg_alpha': 0.024164086603914628, 'reg_lambda': 0.7662933001006519}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:08,094] Trial 34 finished with value: 0.9071762013351419 and parameters: {'n_estimators': 455, 'max_depth': 3, 'learning_rate': 0.0721994666887589, 'num_leaves': 362, 'reg_alpha': 0.015660273514295667, 'reg_lambda': 0.00241479585762293}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:08,800] Trial 35 finished with value: 0.9082474526586847 and parameters: {'n_estimators': 411, 'max_depth': 3, 'learning_rate': 0.05253690520379932, 'num_leaves': 68, 'reg_alpha': 0.0036672685996419116, 'reg_lambda': 1.7722023115942138}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:09,681] Trial 36 finished with value: 0.9077218071432085 and parameters: {'n_estimators': 593, 'max_depth': 3, 'learning_rate': 0.0617949502605691, 'num_leaves': 183, 'reg_alpha': 0.06059993122962107, 'reg_lambda': 4.0855950744137015}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:10,974] Trial 37 finished with value: 0.9037725129451768 and parameters: {'n_estimators': 664, 'max_depth': 4, 'learning_rate': 0.04467382378511746, 'num_leaves': 18, 'reg_alpha': 0.03890067003955437, 'reg_lambda': 0.34418797092817194}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:11,367] Trial 38 finished with value: 0.9042977465367817 and parameters: {'n_estimators': 526, 'max_depth': 1, 'learning_rate': 0.08932540364497002, 'num_leaves': 239, 'reg_alpha': 0.008767519574184758, 'reg_lambda': 0.14188231086945843}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:12,005] Trial 39 finished with value: 0.530618033743902 and parameters: {'n_estimators': 507, 'max_depth': 2, 'learning_rate': 0.0016003961631739713, 'num_leaves': 468, 'reg_alpha': 0.10676318494227169, 'reg_lambda': 5.8373263803758855}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:13,287] Trial 40 finished with value: 0.9091875953441013 and parameters: {'n_estimators': 889, 'max_depth': 3, 'learning_rate': 0.03259641952157409, 'num_leaves': 384, 'reg_alpha': 0.002025628534000918, 'reg_lambda': 0.8458866452213387}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:14,567] Trial 41 finished with value: 0.9085324878341483 and parameters: {'n_estimators': 874, 'max_depth': 3, 'learning_rate': 0.03376077235740568, 'num_leaves': 386, 'reg_alpha': 0.0010773986059689604, 'reg_lambda': 2.2378100156783916}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:15,912] Trial 42 finished with value: 0.9091056707745299 and parameters: {'n_estimators': 932, 'max_depth': 3, 'learning_rate': 0.027536227935937997, 'num_leaves': 314, 'reg_alpha': 0.022003822148626985, 'reg_lambda': 0.9069256551020021}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:17,246] Trial 43 finished with value: 0.9088582080328733 and parameters: {'n_estimators': 918, 'max_depth': 3, 'learning_rate': 0.023563996515711227, 'num_leaves': 321, 'reg_alpha': 0.0025304741078710806, 'reg_lambda': 0.9891292268697782}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:18,678] Trial 44 finished with value: 0.9082845986473662 and parameters: {'n_estimators': 949, 'max_depth': 3, 'learning_rate': 0.029667809559472912, 'num_leaves': 460, 'reg_alpha': 0.018361427798257165, 'reg_lambda': 0.7280283283291438}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:19,994] Trial 45 finished with value: 0.9078043523666226 and parameters: {'n_estimators': 890, 'max_depth': 3, 'learning_rate': 0.01880462612274363, 'num_leaves': 388, 'reg_alpha': 0.001866009140686813, 'reg_lambda': 1.4214876780532701}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:21,434] Trial 46 finished with value: 0.9083792566580634 and parameters: {'n_estimators': 994, 'max_depth': 3, 'learning_rate': 0.03724523419683613, 'num_leaves': 275, 'reg_alpha': 0.03414944341166551, 'reg_lambda': 0.6865146458569451}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:22,331] Trial 47 finished with value: 0.9016486040997738 and parameters: {'n_estimators': 889, 'max_depth': 2, 'learning_rate': 0.013894329958779905, 'num_leaves': 426, 'reg_alpha': 0.010075202305334261, 'reg_lambda': 0.3359036753659989}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:22,951] Trial 48 finished with value: 0.8789803355048573 and parameters: {'n_estimators': 837, 'max_depth': 3, 'learning_rate': 0.06737204266008268, 'num_leaves': 166, 'reg_alpha': 3.8198734644920123, 'reg_lambda': 3.9268324520700206}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:24,938] Trial 49 finished with value: 0.9033582652180059 and parameters: {'n_estimators': 950, 'max_depth': 4, 'learning_rate': 0.02874591560721457, 'num_leaves': 220, 'reg_alpha': 0.1714238884851496, 'reg_lambda': 0.5035238652543775}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:26,466] Trial 50 finished with value: 0.9054466154977691 and parameters: {'n_estimators': 971, 'max_depth': 3, 'learning_rate': 0.05859090175009036, 'num_leaves': 347, 'reg_alpha': 0.29736016668122284, 'reg_lambda': 2.432972326500681}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:27,043] Trial 51 finished with value: 0.9073844193506435 and parameters: {'n_estimators': 348, 'max_depth': 3, 'learning_rate': 0.04647670551051366, 'num_leaves': 252, 'reg_alpha': 0.06995395352915276, 'reg_lambda': 0.057558953746681095}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:28,398] Trial 52 finished with value: 0.9081113599078019 and parameters: {'n_estimators': 918, 'max_depth': 3, 'learning_rate': 0.03958367252691071, 'num_leaves': 327, 'reg_alpha': 0.005638879902269614, 'reg_lambda': 0.01097827206550784}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:29,147] Trial 53 finished with value: 0.9049705014678289 and parameters: {'n_estimators': 478, 'max_depth': 3, 'learning_rate': 0.09801113150622585, 'num_leaves': 389, 'reg_alpha': 0.014305992197051915, 'reg_lambda': 0.021123768138145534}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:30,090] Trial 54 finished with value: 0.907365839313791 and parameters: {'n_estimators': 582, 'max_depth': 3, 'learning_rate': 0.02449930159785453, 'num_leaves': 518, 'reg_alpha': 0.0280375901866608, 'reg_lambda': 1.3164917844851913}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:31,331] Trial 55 finished with value: 0.9082773971038774 and parameters: {'n_estimators': 863, 'max_depth': 3, 'learning_rate': 0.03008532720454885, 'num_leaves': 302, 'reg_alpha': 0.011184230821636006, 'reg_lambda': 0.1199942509770638}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:32,001] Trial 56 finished with value: 0.906947978696335 and parameters: {'n_estimators': 649, 'max_depth': 2, 'learning_rate': 0.03533343358503323, 'num_leaves': 204, 'reg_alpha': 0.045983121149878174, 'reg_lambda': 0.0033863957086178067}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:32,680] Trial 57 finished with value: 0.9077748167027293 and parameters: {'n_estimators': 406, 'max_depth': 3, 'learning_rate': 0.04307207934547175, 'num_leaves': 463, 'reg_alpha': 0.019214023009058674, 'reg_lambda': 0.30534783744527755}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:34,393] Trial 58 finished with value: 0.9017591126603733 and parameters: {'n_estimators': 776, 'max_depth': 4, 'learning_rate': 0.05041940181609522, 'num_leaves': 264, 'reg_alpha': 0.08927795021414281, 'reg_lambda': 0.9935025251922052}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:35,151] Trial 59 finished with value: 0.9024285966951618 and parameters: {'n_estimators': 452, 'max_depth': 3, 'learning_rate': 0.021779888586456256, 'num_leaves': 153, 'reg_alpha': 0.6106219154090546, 'reg_lambda': 0.5587641102512475}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:35,914] Trial 60 finished with value: 0.9085845922430842 and parameters: {'n_estimators': 694, 'max_depth': 2, 'learning_rate': 0.08401005214738091, 'num_leaves': 570, 'reg_alpha': 0.00741085892182107, 'reg_lambda': 3.7062578978974767}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:36,886] Trial 61 finished with value: 0.9083993228604573 and parameters: {'n_estimators': 566, 'max_depth': 3, 'learning_rate': 0.061573265494492366, 'num_leaves': 707, 'reg_alpha': 0.051244975936076416, 'reg_lambda': 1.7033012110104258}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:38,004] Trial 62 finished with value: 0.9064868271239662 and parameters: {'n_estimators': 630, 'max_depth': 3, 'learning_rate': 0.06759467209979815, 'num_leaves': 831, 'reg_alpha': 0.034501347458838205, 'reg_lambda': 5.286492295062853}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:38,796] Trial 63 finished with value: 0.9065983699304059 and parameters: {'n_estimators': 502, 'max_depth': 3, 'learning_rate': 0.05623354586819424, 'num_leaves': 359, 'reg_alpha': 0.01956062537243202, 'reg_lambda': 2.7546203380413297}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:39,726] Trial 64 finished with value: 0.9087411050390408 and parameters: {'n_estimators': 537, 'max_depth': 3, 'learning_rate': 0.04833187429312966, 'num_leaves': 657, 'reg_alpha': 0.02554504038981922, 'reg_lambda': 1.174178758542808}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:40,677] Trial 65 finished with value: 0.9069130214307448 and parameters: {'n_estimators': 619, 'max_depth': 3, 'learning_rate': 0.05965374847864492, 'num_leaves': 416, 'reg_alpha': 0.014089262821631303, 'reg_lambda': 6.320953845407096}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:42,161] Trial 66 finished with value: 0.9071170710825676 and parameters: {'n_estimators': 973, 'max_depth': 3, 'learning_rate': 0.012993827534441248, 'num_leaves': 312, 'reg_alpha': 0.05486301699374904, 'reg_lambda': 0.03130123212328091}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:43,074] Trial 67 finished with value: 0.9089216708946202 and parameters: {'n_estimators': 566, 'max_depth': 3, 'learning_rate': 0.0523852681827156, 'num_leaves': 554, 'reg_alpha': 0.03784674994172918, 'reg_lambda': 1.7631601263064456}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:44,098] Trial 68 finished with value: 0.9040533122056736 and parameters: {'n_estimators': 432, 'max_depth': 4, 'learning_rate': 0.028009164554552338, 'num_leaves': 556, 'reg_alpha': 0.033615232613723525, 'reg_lambda': 1.7485213866337104}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:44,979] Trial 69 finished with value: 0.9079871152276636 and parameters: {'n_estimators': 564, 'max_depth': 3, 'learning_rate': 0.05242439855934031, 'num_leaves': 247, 'reg_alpha': 0.0063865833931340136, 'reg_lambda': 0.39163380952843035}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:45,516] Trial 70 finished with value: 0.906753013725122 and parameters: {'n_estimators': 306, 'max_depth': 3, 'learning_rate': 0.037423190400723436, 'num_leaves': 73, 'reg_alpha': 0.004316725420386899, 'reg_lambda': 0.2354400582122663}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:46,651] Trial 71 finished with value: 0.907381434837459 and parameters: {'n_estimators': 680, 'max_depth': 3, 'learning_rate': 0.06546376945418393, 'num_leaves': 655, 'reg_alpha': 0.1500412075242241, 'reg_lambda': 7.013246029059822}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:47,624] Trial 72 finished with value: 0.9080048755128429 and parameters: {'n_estimators': 585, 'max_depth': 3, 'learning_rate': 0.05503944469787836, 'num_leaves': 491, 'reg_alpha': 0.07667776084229622, 'reg_lambda': 0.5858914336959031}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:48,449] Trial 73 finished with value: 0.9070879300485835 and parameters: {'n_estimators': 483, 'max_depth': 3, 'learning_rate': 0.06945430894852007, 'num_leaves': 605, 'reg_alpha': 0.01760718713958459, 'reg_lambda': 3.1827272840309564}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:49,388] Trial 74 finished with value: 0.9080017920389383 and parameters: {'n_estimators': 607, 'max_depth': 3, 'learning_rate': 0.0470551417006593, 'num_leaves': 277, 'reg_alpha': 0.03926438618282433, 'reg_lambda': 0.9896235590698628}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:50,571] Trial 75 finished with value: 0.9050550511103411 and parameters: {'n_estimators': 724, 'max_depth': 3, 'learning_rate': 0.07709880694256954, 'num_leaves': 612, 'reg_alpha': 0.02387084301382945, 'reg_lambda': 1.487316440843142}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:51,056] Trial 76 finished with value: 0.8849734568532746 and parameters: {'n_estimators': 519, 'max_depth': 1, 'learning_rate': 0.032074825537903744, 'num_leaves': 693, 'reg_alpha': 0.012223066036566305, 'reg_lambda': 2.122213348707399}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:52,352] Trial 77 finished with value: 0.907376161226886 and parameters: {'n_estimators': 907, 'max_depth': 3, 'learning_rate': 0.05029581403631649, 'num_leaves': 218, 'reg_alpha': 0.0024568500356192896, 'reg_lambda': 0.1657413702622044}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:53,023] Trial 78 finished with value: 0.9080324564125235 and parameters: {'n_estimators': 385, 'max_depth': 3, 'learning_rate': 0.04371545128511255, 'num_leaves': 527, 'reg_alpha': 0.0014179740356400948, 'reg_lambda': 0.06943576620241708}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:53,980] Trial 79 finished with value: 0.9073034684972516 and parameters: {'n_estimators': 836, 'max_depth': 2, 'learning_rate': 0.08976481666456426, 'num_leaves': 442, 'reg_alpha': 0.10760040928173438, 'reg_lambda': 0.001240907048827973}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:55,466] Trial 80 finished with value: 0.9060916761823504 and parameters: {'n_estimators': 953, 'max_depth': 3, 'learning_rate': 0.06284412344185275, 'num_leaves': 371, 'reg_alpha': 0.0436740145565991, 'reg_lambda': 0.7776053070402315}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:56,422] Trial 81 finished with value: 0.9086237326147538 and parameters: {'n_estimators': 938, 'max_depth': 2, 'learning_rate': 0.04237659989694589, 'num_leaves': 343, 'reg_alpha': 0.0013559745317938553, 'reg_lambda': 1.2740157379429717}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:57,442] Trial 82 finished with value: 0.9082196669005 and parameters: {'n_estimators': 977, 'max_depth': 2, 'learning_rate': 0.04019212196100978, 'num_leaves': 325, 'reg_alpha': 0.0019420516392497453, 'reg_lambda': 2.412159942003698}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:36:58,409] Trial 83 finished with value: 0.9074391691275702 and parameters: {'n_estimators': 964, 'max_depth': 2, 'learning_rate': 0.03554979267408639, 'num_leaves': 291, 'reg_alpha': 0.0011757355692328193, 'reg_lambda': 1.1257905467398968}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:00,034] Trial 84 finished with value: 0.9074272224716042 and parameters: {'n_estimators': 998, 'max_depth': 3, 'learning_rate': 0.03937877173710183, 'num_leaves': 406, 'reg_alpha': 0.06294325403701537, 'reg_lambda': 4.30679355122729}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:00,909] Trial 85 finished with value: 0.9080295270237835 and parameters: {'n_estimators': 550, 'max_depth': 3, 'learning_rate': 0.026765871966912522, 'num_leaves': 243, 'reg_alpha': 0.03042630498728658, 'reg_lambda': 0.8206768606721592}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:02,013] Trial 86 finished with value: 0.9080433090331479 and parameters: {'n_estimators': 575, 'max_depth': 3, 'learning_rate': 0.0318435808731421, 'num_leaves': 970, 'reg_alpha': 0.00454467795392963, 'reg_lambda': 3.2582711664265025}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:02,648] Trial 87 finished with value: 0.9041630886804078 and parameters: {'n_estimators': 932, 'max_depth': 1, 'learning_rate': 0.053904161611723136, 'num_leaves': 193, 'reg_alpha': 0.0029100894146379622, 'reg_lambda': 0.41443282628875905}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:03,521] Trial 88 finished with value: 0.9080144316846758 and parameters: {'n_estimators': 494, 'max_depth': 3, 'learning_rate': 0.04466869292135706, 'num_leaves': 494, 'reg_alpha': 0.02131231564161264, 'reg_lambda': 0.0066789503989557715}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:04,320] Trial 89 finished with value: 0.9091539724805532 and parameters: {'n_estimators': 467, 'max_depth': 3, 'learning_rate': 0.058689014113017614, 'num_leaves': 301, 'reg_alpha': 0.008779608592745182, 'reg_lambda': 1.6444579226785017}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:05,053] Trial 90 finished with value: 0.9090096796718561 and parameters: {'n_estimators': 462, 'max_depth': 3, 'learning_rate': 0.06014563225483453, 'num_leaves': 124, 'reg_alpha': 0.008000518780531062, 'reg_lambda': 1.6237018617057686}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:05,767] Trial 91 finished with value: 0.907920516941139 and parameters: {'n_estimators': 437, 'max_depth': 3, 'learning_rate': 0.05947065223216474, 'num_leaves': 133, 'reg_alpha': 0.00917388172413347, 'reg_lambda': 1.6952241045379453}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:06,528] Trial 92 finished with value: 0.9080669668478885 and parameters: {'n_estimators': 464, 'max_depth': 3, 'learning_rate': 0.06485888046063001, 'num_leaves': 265, 'reg_alpha': 0.007531972860362671, 'reg_lambda': 1.9575976286166166}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:07,363] Trial 93 finished with value: 0.9090891968009107 and parameters: {'n_estimators': 532, 'max_depth': 3, 'learning_rate': 0.05702760663860473, 'num_leaves': 166, 'reg_alpha': 0.014794957761431441, 'reg_lambda': 0.6518224000617407}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:08,030] Trial 94 finished with value: 0.9091372200031888 and parameters: {'n_estimators': 416, 'max_depth': 3, 'learning_rate': 0.057371354195165744, 'num_leaves': 166, 'reg_alpha': 0.011515126887377224, 'reg_lambda': 0.7048764082354784}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:08,722] Trial 95 finished with value: 0.9082513811212323 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.05729455824937601, 'num_leaves': 173, 'reg_alpha': 0.011453357421326485, 'reg_lambda': 0.6854752992596759}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:09,317] Trial 96 finished with value: 0.9069548319638038 and parameters: {'n_estimators': 360, 'max_depth': 3, 'learning_rate': 0.061642133868861325, 'num_leaves': 94, 'reg_alpha': 0.01584698272764104, 'reg_lambda': 0.5868867597108713}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:10,061] Trial 97 finished with value: 0.9082389409988563 and parameters: {'n_estimators': 471, 'max_depth': 3, 'learning_rate': 0.07262648569191071, 'num_leaves': 115, 'reg_alpha': 0.004860071834692154, 'reg_lambda': 1.0445149952294903}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:10,770] Trial 98 finished with value: 0.9070898382801428 and parameters: {'n_estimators': 419, 'max_depth': 3, 'learning_rate': 0.06871902845703928, 'num_leaves': 150, 'reg_alpha': 0.008460365645078108, 'reg_lambda': 1.44423286092708}. Best is trial 32 with value: 0.9092595905524172.\n",
      "[I 2025-03-10 10:37:11,484] Trial 99 finished with value: 0.9079539758135725 and parameters: {'n_estimators': 442, 'max_depth': 3, 'learning_rate': 0.04925101076161867, 'num_leaves': 87, 'reg_alpha': 0.011335121696779386, 'reg_lambda': 0.8863635146589122}. Best is trial 32 with value: 0.9092595905524172.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 0.9092595905524172\n",
      "Best hyperparameters: {'n_estimators': 492, 'max_depth': 3, 'learning_rate': 0.059766719431178915, 'num_leaves': 322, 'reg_alpha': 0.017729388440876875, 'reg_lambda': 0.8896739716299361}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 4),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 1000),\n",
    "        # \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        # \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),  # L1 regularization\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),  # L2 regularization\n",
    "        \"force_row_wise\": True\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params, verbose=-1) #I suppress the output due to many warnings that optimal split is not found\n",
    "    return sklearn.model_selection.cross_val_score(model, X_transformed, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best trial\n",
    "trial = study.best_trial\n",
    "print(\"Best R2:\", trial.value)\n",
    "print(\"Best hyperparameters:\", trial.params)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
