{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_linear_regression(\n",
    "    data: pd.DataFrame, \n",
    "    target: str, \n",
    "    alphas: list[int] = [0.1, 1, 10, 100],\n",
    "    regularization: str = None,\n",
    "    test_size: float = 0.2, \n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a linear regression model with optional regularization.\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "\n",
    "    categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Create preprocessor with one-hot encoder for categories.\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "            ('num', StandardScaler(), numerical_columns)\n",
    "            # ('num', 'passthrough', numerical_columns)\n",
    "        ])\n",
    "\n",
    "    # Select appropriate regressor\n",
    "    if regularization == 'ridge':\n",
    "        regressor = Ridge()\n",
    "        alphas = alphas#[1, 10.0, 100.0]#[5.0, 6, 7, 8, 9, 10.0, 12, 20.0]\n",
    "        param_grid = {'regressor__alpha': alphas}\n",
    "    elif regularization == 'lasso':\n",
    "        regressor = Lasso(max_iter=50000, tol=0.001, selection='random')\n",
    "        alphas = alphas#[0.1, 1, 10.0, 100.0]\n",
    "        param_grid = {'regressor__alpha': alphas}\n",
    "    else:\n",
    "        regressor = LinearRegression()\n",
    "        param_grid = {}\n",
    "\n",
    "    # Create a pipeline with preprocessor and regression\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Fit the model\n",
    "    if regularization in ['ridge', 'lasso']:\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            model, \n",
    "            param_grid, \n",
    "            cv=5, \n",
    "            scoring='neg_mean_squared_error'\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        best_model = model\n",
    "        best_params = {}\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Get feature names\n",
    "    feature_names = (\n",
    "        list(best_model.named_steps['preprocessor']\n",
    "             .named_transformers_['cat']\n",
    "             .get_feature_names_out(categorical_columns)) + \n",
    "        list(numerical_columns)\n",
    "    )\n",
    "    \n",
    "    # Create a dataframe of coefficients\n",
    "    coefficients = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': np.abs(best_model.named_steps['regressor'].coef_)\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Return results\n",
    "    return {\n",
    "        'model': best_model,\n",
    "        'performance': {\n",
    "            'root_mean_squared_error': rmse,\n",
    "            'r2_score': r2\n",
    "        },\n",
    "        'best_params': best_params,\n",
    "        'feature_importances': coefficients,\n",
    "        'train_data': (X_train, y_train),\n",
    "        'test_data': (X_test, y_test)\n",
    "    }\n",
    "\n",
    "# df = pd.read_csv('data/train_transformed.csv')\n",
    "# df = pd.read_csv('data/train_cleaned.csv')\n",
    "\n",
    "# results_no_reg = train_linear_regression(df, target='SalePrice')\n",
    "# results_ridge = train_linear_regression(df, target='SalePrice', regularization='ridge')\n",
    "# results_lasso = train_linear_regression(df, target='SalePrice', regularization='lasso')\n",
    "\n",
    "# print('Results with no regularization:')\n",
    "# for metric, value in results_no_reg['performance'].items():\n",
    "#     print(f\"{metric}: {value}\")\n",
    "\n",
    "# print('Results with ridge regularization:')    \n",
    "# for metric, value in results_ridge['performance'].items():\n",
    "#     print(f\"{metric}: {value}\")\n",
    "# print(results_ridge['best_params'])\n",
    "\n",
    "    \n",
    "# print('Results with lasso regularization:')\n",
    "# for metric, value in results_lasso['performance'].items():\n",
    "#     print(f\"{metric}: {value}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(results_lasso['feature_importances'])\n",
    "# print(\"Number of features with zero coefficient in lasso regularization:\",(results_lasso['feature_importances']['importance']==0.0).sum(), 'out of', (results_lasso['feature_importances']['importance']).count())\n",
    "# print(\"Number of features with zero coefficient in lasso regularization:\",(results_lasso['feature_importances']['importance']!=0).sum())\n",
    "# print(\"Number of features with zero coefficient in ridge regularization:\",(results_ridge['feature_importances']['importance']==0.0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65503026247.929695, tolerance: 5720161822.224232\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_cleaned.csv')\n",
    "# print(df.columns)\n",
    "\n",
    "results_no_reg = train_linear_regression(df, target='SalePrice')\n",
    "\n",
    "print('Results with no regularization:')\n",
    "for metric, value in results_no_reg['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "\n",
    "results_ridge = train_linear_regression(df, target='SalePrice', regularization='ridge')\n",
    "\n",
    "print('Results with ridge regularization:')    \n",
    "for metric, value in results_ridge['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(results_ridge['best_params'])\n",
    "\n",
    "results_lasso = train_linear_regression(df, target='SalePrice', regularization='lasso')\n",
    "    \n",
    "print('Results with lasso regularization:')\n",
    "for metric, value in results_lasso['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(results_lasso['best_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with no regularization:\n",
      "root_mean_squared_error: 0.13362253964398918\n",
      "r2_score: 0.9043197657548931\n",
      "Results with ridge regularization:\n",
      "root_mean_squared_error: 0.13759280939027674\n",
      "r2_score: 0.8985494833983114\n",
      "{'regressor__alpha': 10.0}\n",
      "Results with lasso regularization:\n",
      "root_mean_squared_error: 0.25447669646872534\n",
      "r2_score: 0.6529765501202527\n",
      "{'regressor__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_log1p.csv')\n",
    "# print(df.columns)\n",
    "\n",
    "print('Results with no regularization:')\n",
    "for metric, value in results_no_reg['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "\n",
    "results_ridge = train_linear_regression(df, target='SalePrice', regularization='ridge')\n",
    "\n",
    "print('Results with ridge regularization:')    \n",
    "for metric, value in results_ridge['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(results_ridge['best_params'])\n",
    "\n",
    "results_lasso = train_linear_regression(df, target='SalePrice', regularization='lasso')\n",
    "    \n",
    "print('Results with lasso regularization:')\n",
    "for metric, value in results_lasso['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(results_lasso['best_params'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'MSZoning', 'Alley', 'LotShape', 'LandContour',\n",
      "       'LotConfig', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle',\n",
      "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
      "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
      "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
      "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'Heating', 'HeatingQC', 'CentralAir',\n",
      "       'Electrical', 'BsmtFullBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
      "       'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional',\n",
      "       'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
      "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
      "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice', 'TotalBsmtSF_1stFlrSF_PC',\n",
      "       '2ndFlrSF_GrLivArea_PC', 'LotArea_LotFrontage_PC'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102959553849.9152, tolerance: 5374150251.745832\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40651310845.72824, tolerance: 5720161822.224232\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51865197893.16351, tolerance: 5256051888.020476\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71338742631.24057, tolerance: 5716146662.949619\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116454072159.2966, tolerance: 5795921139.945961\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with no regularization:\n",
      "root_mean_squared_error: 31210.930823417777\n",
      "r2_score: 0.8730012027452739\n",
      "Results with ridge regularization:\n",
      "root_mean_squared_error: 32808.33352518662\n",
      "r2_score: 0.8596687129562618\n",
      "{'regressor__alpha': 100.0}\n",
      "Results with lasso regularization:\n",
      "root_mean_squared_error: 29469.005472553603\n",
      "r2_score: 0.8867815709418356\n",
      "{'regressor__alpha': 100.0}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_full_EDA.csv')\n",
    "print(df.columns)\n",
    "\n",
    "print('Results with no regularization:')\n",
    "for metric, value in results_no_reg['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "\n",
    "results_ridge = train_linear_regression(df, target='SalePrice', regularization='ridge')\n",
    "\n",
    "print('Results with ridge regularization:')    \n",
    "for metric, value in results_ridge['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(results_ridge['best_params'])\n",
    "\n",
    "results_lasso = train_linear_regression(df, target='SalePrice', regularization='lasso')\n",
    "    \n",
    "print('Results with lasso regularization:')\n",
    "for metric, value in results_lasso['performance'].items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "print(results_lasso['best_params'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
